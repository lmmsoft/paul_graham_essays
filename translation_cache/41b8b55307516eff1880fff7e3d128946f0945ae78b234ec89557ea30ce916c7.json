{
  "original": "  2. Exclamation points are constituent characters.  \n  \n\n  3. Periods and commas are constituents if they occur between two digits. This lets me get ip addresses and prices intact.  \n  \n\n  4. A price...",
  "translation": "2. 感叹号是构成性字符。\n\n\n3. 当句号和逗号出现在两个数字之间时，它们被视为构成性字符。这使得IP地址和价格能保持完整。\n\n\n4. 类似$20-25的价格区间会生成两个标记：$20和$25。\n\n\n5. 出现在“收件人”、“发件人”、“主题”和“返回路径”行或网址内的标记会进行相应标注。例如，主题行中的“foo”会变成“Subject*foo”（星号可以是任何不被允许作为构成性字符的符号）。\n\n这些措施增加了过滤器的词汇量，使其更具辨别力。例如，在当前过滤器中，主题行中的“free”标记的垃圾邮件概率为98%，而正文中相同标记的垃圾邮件概率仅为65%。\n\n以下是当前部分概率值[6]：\n\nSubject*FREE      0.9999\nfree!!            0.9999\nTo*free           0.9998\nSubject*free      0.9782\nfree!             0.9199\nFree              0.9198\nUrl*free          0.9091\nFREE              0.8747\nFrom*free         0.7636\nfree              0.6546\n\n在“Plan for Spam”过滤器中，所有这些标记的概率都相同，为0.7602。该过滤器能识别约23,000个标记，而当前版本能识别约187,000个。\n\n扩大标记范围的缺点是可能增加遗漏风险。将语料分散到更多标记上会产生与缩小语料相同的效果。例如，如果将感叹号视为构成性字符，最终可能无法获取带有七个感叹号的“free”的垃圾邮件概率，尽管已知仅带两个感叹号的“free”概率为99.99%。\n\n对此的解决方案是我所称的“退化处理”。如果找不到标记的精确匹配，则将其视为不太具体的版本。我认为结尾的感叹号、大写字母以及出现在五个特定上下文之一中的标记会使标记更具体。例如，如果找不到“Subject*free!”的概率，就查找“Subject*free”、“free!”和“free”的概率，并取最偏离0.5的值。\n\n以下是过滤器在主题行中看到“FREE!!!”但未找到其概率时会考虑的备选方案[7]：\n\nSubject*Free!!!\nSubject*free!!!\nSubject*FREE!\nSubject*Free!\nSubject*free!\nSubject*FREE\nSubject*Free\nSubject*free\nFREE!!!\nFree!!!\nfree!!!\nFREE!\nFree!\nfree!\nFREE\nFree\nfree",
  "timestamp": "2025-07-14T02:31:05.994742",
  "model": "deepseek-ai/DeepSeek-V3"
}