{
  "original": "| | [](index.html)  \n  \n|   \n  \nJanuary 2003  \n  \n _(This article was given as a talk at the 2003 Spam Conference. It describes the work I've done to improve the performance of the algorithm described...",
  "translation": "| | [](index.html)  \n\n|  \n\n2003年1月  \n\n（本文是我在2003年反垃圾邮件大会上的演讲内容，描述了我对《反垃圾邮件计划》所述算法的改进工作及未来规划。）  \n\n我要分享的第一个发现是研究论文的惰性评估算法：只需写出你想写的内容且不引用任何前人工作，愤怒的读者自会发来你本该引用的所有文献。这个算法是我在《反垃圾邮件计划》[1]被Slashdot转载后悟出的。  \n\n垃圾邮件过滤属于文本分类的子领域，这个学科已相当成熟。但最早的贝叶斯垃圾邮件过滤论文似乎都出现在1998年的同场会议上：一篇来自Pantel和Lin[2]，另一篇来自微软研究院团队[3]。  \n\n得知这些研究时我有些惊讶。既然四年前就有人研究贝叶斯过滤，为何没有普及？读完论文后我找到了答案。Pantel和Lin的过滤器效果较好，但仅能拦截92%的垃圾邮件，且有1.16%的误判率。  \n\n而我编写的贝叶斯过滤器实现了99.5%的垃圾邮件拦截率和低于0.03%的误判率[4]。当相同实验得出迥异结果时总是令人不安，尤其这两组数据可能导致相反结论。虽然用户需求各异，但对多数人而言，92%拦截率配1.16%误判率意味着过滤方案不可行，而99.5%拦截率配0.03%误判率则完全可行。  \n\n为何结果差异如此之大？虽未复现Pantel和Lin的实验，但从论文中我发现了五个可能原因：  \n\n首先，他们的训练数据量过少——仅160封垃圾邮件和466封正常邮件。这种数据规模下过滤性能应仍在上升期，因此其数据甚至不足以准确衡量其算法表现，更不用说整体贝叶斯过滤效果。  \n\n但最关键的区别可能是他们忽略了邮件头。这对反垃圾邮件开发者来说是个反常决定。有趣的是，我最初编写的过滤器也忽略了邮件头——因为当时对邮件头知之甚少，觉得它们充满杂乱信息。这给过滤器开发者上了重要一课：不要忽视任何数据。这个教训看似显而易见，我却多次重蹈覆辙。  \n\n第三，Pantel和Lin对词汇进行了词干提取（如将\"mailing\"和\"mailed\"都归为\"mail\"）。这可能是受限于小规模语料库的妥协，但实属过早优化。  \n\n第四，他们采用不同的概率计算方式：使用全部词汇特征，而我仅选取15个最显著特征。使用全部特征会导致漏判长篇垃圾邮件（比如那些先讲述人生故事再推销传销项目的邮件）。这种算法也容易被攻击：只需添加大段随机文本就能稀释垃圾词汇特征。  \n\n最后，他们没有针对误判进行优化。我认为所有垃圾邮件过滤算法都应提供调节旋钮，允许用户通过降低过滤率来减少误判。我的解决方案是对正常邮件中的词汇特征进行双倍计数。  \n\n将垃圾邮件过滤简单视作文本分类问题并不明智。虽然可以运用文本分类技术，但解决方案必须体现电子邮件的特殊性——尤其是垃圾邮件。邮件不仅是文本，还具有结构特征；过滤不仅是分类，更因误判代价远高于漏判而需区别对待；错误来源不仅是随机偏差，还包括刻意对抗过滤器的垃圾邮件发送者。  \n\n**词汇特征**  \n\nSlashdot事件后，我还了解到Bill Yerazunis的[CRM114][5]项目。它完美反驳了我刚提出的设计原则——这个纯粹的文本分类器甚至不知道自己用于反垃圾邮件，却实现了近乎完美的过滤效果。  \n\n理解CRM114原理后，我意识到从单词级过滤转向此类方法是大势所趋。但我想先探索单词级过滤的极限——结果证明其潜力远超预期。  \n\n我的主要突破在于更智能的词汇切分技术。针对当前垃圾邮件，我的过滤效果已接近CRM114。这些技术与Bill的方案大多互补，最佳解决方案或许需要二者结合。  \n\n《反垃圾邮件计划》采用极简的词汇定义：字母、数字、连字符、撇号和美元符号视为组成字符，其余皆作分隔符，且忽略大小写。  \n\n现在我的词汇定义更为复杂：  \n1. 保留大小写",
  "timestamp": "2025-07-14T02:30:46.976007",
  "model": "deepseek-ai/DeepSeek-V3"
}