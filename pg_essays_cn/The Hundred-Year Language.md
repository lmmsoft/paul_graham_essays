---
title: "百年语言"
original_title: "The Hundred-Year Language"
author: "Paul Graham"
translator: "deepseek-ai/DeepSeek-V3 (SiliconFlow)"
translate_date: "2025-07-14"
source_file: "The Hundred-Year Language.md"
---

# 百年语言

| | [](index.html)  

| [](https://s.turbifycdn.com/aah/paulgraham/the-hundred-year-language-11.gif)  

2003年4月  

（本文改编自2003年PyCon大会的主题演讲。）  

预测一百年后的生活面貌极为困难。只有少数几件事我们可以确定：人人都会驾驶飞行汽车，城市规划法规将放宽以允许数百层高的建筑，世界将长期处于黑暗之中，而所有女性都将接受武术训练。在此，我想聚焦于这幅图景中的一个细节——人们将使用何种编程语言来编写控制这些飞行汽车的软件？  

思考这个问题并非因为我们将实际使用这些未来语言，而是因为如果我们足够幸运，我们将会使用从当下通往未来的路径上的那些语言。  

我认为，编程语言将像物种一样形成进化树，枝杈上遍布死胡同。这种现象已然可见。COBOL尽管曾一度流行，但似乎没有留下任何思想传承。它是一个进化的死胡同——一种尼安德特式的语言。  

我预测Java将面临类似的命运。有时人们会发邮件问我：“你怎么能断言Java不会成为成功的语言？它已经是一种成功的语言了。”我承认，如果以相关书籍占据的书架空间（尤其是单卷本的厚度）或认为必须学习Java才能找到工作的大学生数量来衡量成功，Java确实成功了。但当我断言Java不会成为成功的语言时，我指的是更具体的含义：Java终将成为像COBOL那样的进化死胡同。  

这只是一个猜测，我可能错了。我的目的不是贬低Java，而是提出进化树的概念，让人们思考：语言X在这棵树的哪个位置？提出这个问题不仅是为了让我们的灵魂在一百年后能说“我早告诉过你”，更是因为贴近主干分支是寻找当下优秀编程语言的实用启发法。  

在任意时间点上，处于进化树的主干分支上可能最令人愉悦。即使尼安德特人数量众多时，做尼安德特人想必也很糟糕。克罗马农人会不断过来殴打你并抢走你的食物。  

我想了解一百年后的语言形态，是为了知道现在该押注于哪个分支。  

语言的进化与物种进化的不同之处在于分支可以融合。例如，Fortran分支似乎正在与Algol的后代合并。理论上物种也可能发生融合，但规模不太可能超过细胞级别。  

语言更可能融合，部分原因是可能性空间较小，部分因为变异并非随机发生。语言设计者会刻意吸收其他语言的思想。  

对语言设计者而言，思考编程语言进化方向尤为有益，因为他们可以据此调整航向。在这种情况下，“停留在主干分支上”不仅是选择优秀语言的方法，更成为语言设计决策的启发法则。  

任何编程语言都可划分为两部分：扮演公理角色的一组基本运算符，以及其余部分（理论上可用这些基本运算符表示的部分）。  

我认为基本运算符是决定语言长期存续的最重要因素。其余部分都可以改变。这就像购房的首要原则是考虑地段——其他都可以后期改造，唯独地段无法改变。  

不仅公理需要精挑细选，数量也应尽可能少。数学家始终认为公理越少越好，我认为他们发现了真理。  

至少，仔细审视语言核心以剔除冗余公理是极具价值的实践。在我漫长的邋遢生涯中，我发现杂乱滋生杂乱——这个规律适用于床底和房间角落，也同样适用于软件。  

我直觉认为，进化树的主干分支将穿过那些拥有最精简、最清晰核心的语言。能用语言自身表达的部分越多越好。  

当然，我提出“百年后编程语言会怎样”这个问题本身就做了大胆假设。一百年后我们还需要编写程序吗？难道不能直接告诉计算机我们想要什么？  

迄今为止这个领域进展甚微。我猜测一百年后人们仍需要使用我们可识别的程序来指挥计算机。某些现在需要编程的任务未来可能不再需要，但我认为今天我们从事的这类编程工作仍将大量存在。  

预测任何技术的百年面貌似乎狂妄自大。但请记住，编程已有近五十年历史。考虑到过去五十年语言进化之缓慢，展望百年并非不可想象。  

语言进化缓慢因为它们本质上是符号系统而非技术。程序是对待解决问题的形式化描述，因此编程语言的进化速度更接近数学符号的演变节奏，而非交通或通信技术。数学符号确实在进化，但不会出现技术领域那种巨大飞跃。  

无论百年后计算机由什么构成，其速度远超今日是可以安全预测的。若摩尔定律持续生效，速度将提升74万亿亿倍（73,786,976,294,838,206,464倍）。这难以想象。实际上最可能的预测是摩尔定律终将失效——任何每18个月翻番的事物都终将触及物理极限。但我毫不怀疑计算机将变得极快。即使仅提升百万倍，也足以彻底改写编程语言的基本规则。届时，那些现在被视为缓慢的语言（即生成低效代码的语言）将有更大生存空间。  

然而某些应用仍将追求速度。计算机产生的问题需要计算机解决——例如视频图像处理速度取决于另一台计算机的生成速度。还有一类问题天生具有吞噬计算周期的能力：图像渲染、加密、模拟等。  

当部分应用可以越来越低效而其他应用仍需压榨硬件性能时，更快的计算机意味着语言需要覆盖更广的效率范围。这种现象已然显现——按过去标准衡量，某些流行新语言的实现简直浪费得惊人。  

这不仅是编程语言的现象，而是普遍历史趋势。技术改进使每一代人都能做被上一代人视为浪费的事。三十年前的人会惊诧于我们拨打长途电话的随意，百年前的人更会震惊于包裹竟需经孟菲斯中转才能从波士顿抵达纽约。  

我已然能预见未来百年硬件提速带来的额外周期将如何被消耗——几乎全部浪费掉。  

我在计算资源稀缺时代学会编程，记得曾删除BASIC程序中所有空格以塞进4K内存的TRS-80。想到这些极其低效的软件反复做着相同工作，我感到某种不适。但这种直觉可能是错的——就像从小贫穷的人难以忍受为重要事项（比如看病）花钱。  

某些浪费确实令人反感。比如SUV，即便使用永续无污染的燃料，其存在本身仍是粗鄙的——因为它是解决粗鄙问题（如何让迷你货车更阳刚）的方案。但并非所有浪费都坏。既然已具备支持设施，计较长途电话分钟数就显得吝啬。拥有资源时，将所有通话视为同类（无论对方位置）才是更优雅的做法。  

存在好的浪费与坏的浪费。我关注好的浪费——通过更多支出来换取更简洁的设计。我们将如何利用更快硬件提供的浪费机会？对速度的渴求已深入骨髓（拜孱弱硬件所赐），需要有意识地克服。在语言设计中，我们应主动寻找能用效率换取微小便利提升的场景。  

大多数数据结构因速度需求而存在。例如当今许多语言同时拥有字符串和列表。语义上字符串基本是元素为字符的列表子集，为何需要独立数据类型？本质上不需要。字符串仅为效率而存在。但用影响语言语义的hack来提速是拙劣的——在语言中包含字符串像是过早优化。  

若将语言核心视为公理集合，那么仅为效率而添加无表达力的额外公理是粗鄙的。效率重要，但这不是正确的实现方式。  

我认为正确解法是将程序意义与实现细节分离。与其同时拥有列表和字符串，不如仅保留列表，并通过某种方式向编译器提供优化建议，使其在必要时将字符串存储为连续字节。  

由于程序大部分不关心速度，通常无需纠结此类微观管理。随着计算机提速，这一点将愈发明显。  

减少实现细节还能增强程序灵活性。编写过程中需求变更是不可避免的，甚至是值得期待的。  

“文章”（essay）一词源自法语动词“essayer”（尝试）。原始意义上的文章是为厘清问题而作的文字。软件亦然。我认为某些最优秀的程序正是这种意义上的“文章”——作者起笔时并不确知最终形态。  

Lisp黑客早已洞悉数据结构灵活性的价值。我们习惯用列表编写程序初版，其效率可能低得惊人，需要刻意不去思考其运行机制（就像我吃牛排时需要刻意不去想其来源）。  

百年后的程序员最渴望的，是用最少精力拼凑出极其低效的1.0版本的语言。用当今术语说就是“易于编程”的语言。  

低效软件并不粗鄙。粗鄙的是迫使程序员做无用功的语言。浪费程序员时间才是真正的低效，而非浪费机器时间。随着计算机提速，这一点将愈发清晰。  

我认为现在已可考虑舍弃字符串。我们在Arc语言中这样做了，结果证明是胜利——某些用正则表达式难以描述的操作，用递归函数可以轻松实现。  

数据结构的扁平化能走多远？即使以我自觉开阔的思维，某些可能性仍令我震惊。比如舍弃数组？毕竟它们只是键为整数向量的哈希表子集。用列表取代哈希表本身？  

还有更惊人的可能。例如McCarthy在1960年描述的Lisp没有数字概念。逻辑上你不需要独立数字概念，因为可用列表表示——整数n可表示为含n个元素的列表。虽然这种数学运算方式效率令人窒息。  

实践中无人建议如此实现数字。实际上McCarthy的1960年论文当时根本无意实现，它只是创建图灵机优雅替代品的理论尝试。当有人意外地将论文转化为可运行的Lisp解释器时，数字当然不是用列表表示——它们像所有其他语言一样用二进制表示。  

编程语言能否彻底取消数字作为基本数据类型？我提出这个问题更多是与未来玩胆量游戏，就像不可抗拒力遇到不可移动物的假设案例——在这里是难以想象的低效实现遇到难以想象的庞大资源。我看不出为何不可。未来足够漫长。如果我们能减少核心语言的公理数量，随着时间趋近无穷，这似乎值得押注。若百年后这个想法仍难以接受，或许千年后会改变。  

需要明确的是，我并非提议所有计算实际都用列表进行。我建议的是在添加任何实现注解前，核心语言应该如此定义。实践中任何涉及数学的程序都可能用二进制表示数字，但这属于优化，而非核心语言语义部分。  

另一种消耗周期的方式是在应用与硬件间设置多层软件。这已是可见趋势——许多新近语言被编译为字节码。Bill Woods曾告诉我经验法则：每层解释会使速度降低十倍。这种代价换来的是灵活性。  

Arc的首个版本就是这种多层次缓慢的极端案例，也带来相应好处。它是运行在Common Lisp之上的经典“元循环”解释器，与McCarthy原始Lisp论文中定义的eval函数有明显亲缘关系。整个系统仅几百行代码，极易理解和修改。我们使用的CLisp本身运行在字节码解释器上。因此这里有两层解释（顶层效率低得惊人），但语言居然可用——勉强可用，但确实可用。  

分层编写软件即使在应用内部也是强大技术。自底向上编程意味着将程序写成系列层次，每层都是上一层的语言。这种方法往往产生更小更灵活的程序，也是实现圣杯——可重用性——的最佳路径。语言天生可重用。将越多应用逻辑下放到针对某类应用的语言中，就有越多软件可重用。  

1980年代可重用性概念与面向对象编程错误绑定，至今难以分离。尽管某些面向对象软件确实可重用，但使其可重用的是自底向上特性而非面向对象特性。以库为例：它们可重用因为它们是语言，无论是否采用面向对象风格编写。  

顺便说，我并非预测面向对象编程的消亡。尽管我认为除了特定领域外它对优秀程序员价值有限，但大型组织难以抗拒它。面向对象编程提供了一种可持续编写意大利面条代码的方式，允许以补丁序列形式累积程序。大型组织总是倾向于这种方式开发软件，我预计百年后依然如此。  

既然谈及未来，就不得不讨论并行计算——这个概念似乎永远属于未来。无论何时讨论，并行计算似乎总是即将到来。  

未来会追上它吗？人们将并行计算视为迫近事物已至少二十年，至今对编程实践影响有限。真的有限吗？芯片设计师已必须考虑它，多CPU计算机上的系统软件编写者亦然。  

真正的问题是：并行性会渗透到抽象阶梯的哪一层？百年后它会影响应用程序员吗？抑或仍是编译器编写者关注但对应用源代码透明的事物？  

似乎多数并行机会将被浪费。这是我更宏观预测（额外计算能力大多被浪费）的特例。与底层硬件的惊人速度类似，我预计并行性将是一种需要显式请求才会启用的能力，通常处于闲置状态。这意味着百年后的并行性（特殊应用除外）不会是大规模并行。对普通程序员而言，可能更像是能派生出并行运行的进程。  

就像为数据结构选择特定实现，这将是程序生命周期后期优化阶段的工作。1.0版本通常会忽略并行计算的优势，就像忽略数据特定表示法的优势。  

除特殊应用外，并行性不会渗透百年后的程序。如果渗透了，那就是过早优化。  

百年后会有多少种编程语言？近来似乎涌现大量新语言。部分原因是更快硬件允许程序员根据不同应用在速度与便利间做出不同权衡。若这是真实趋势，百年后的硬件只会加剧它。  

然而百年后可能只有少数几种广泛使用的语言。我这么说的部分原因是乐观：似乎若能真正做好，可以创造出既适合编写低效1.0版本，又能在编译器获得正确优化建议时生成高效代码的语言。因此作为乐观主义者，我预测尽管可接受效率与最大效率间存在巨大鸿沟，百年后的程序员将拥有能覆盖大部分区间的语言。  

随着这个鸿沟扩大，性能分析工具将愈发重要。目前性能分析未受足够重视。许多人仍认为获得快速应用的途径是编写生成快速代码的编译器。随着可接受性能与最大性能差距扩大，获得快速应用的正确途径将愈发清晰：需要从前者到后者的优质向导。  

当我说可能只有少数语言时，不包括领域特定的“小语言”。我认为这种嵌入式语言是伟大创意，预计会激增。但我预期它们会以足够薄的皮肤编写，让用户能看清底层的通用语言。  

谁来设计未来语言？过去十年最激动人心的趋势是Perl、Python、Ruby等开源语言的崛起。语言设计正被黑客接管。目前成果虽混乱但鼓舞人心。例如Perl包含一些惊人新颖的思想——尽管许多糟糕得惊人，但雄心勃勃的尝试总是如此。以当前变异速度，天知道百年后Perl会进化成什么。  

“不能者教”并非真理（我认识的最优秀黑客有些是教授），但教师群体确实存在大量“不能”之事。学术研究施加了种姓限制。任何学术领域都存在可研究课题与禁忌课题。不幸的是，这种区分通常基于研究论文描述时的学术性，而非对获得好结果的重要性。文学可能是极端案例——研究文学者几乎从不说对创作者有用的内容。  

尽管科学界状况较好，但被允许的工作类型与产出优秀语言的工作类型重叠之小令人沮丧（Olin Shivers对此有过精彩抱怨）。例如类型系统似乎是研究论文的永恒源泉，尽管静态类型似乎排除了真正的宏——在我看来没有宏的语言根本不值得使用。  

趋势不仅是语言作为开源项目而非“研究”开发，更是由需要使用它们的应用程序员而非编译器编写者设计语言。这似乎是好趋势，我预计将持续。  

与几乎无法预测的百年后物理学不同，我认为原则上现在就可能设计出百年后仍受欢迎的语言。  

设计语言的一种方式是写下你希望写出的程序，无视是否存在能编译它的编译器或能运行它的硬件。此时你可以假设资源无限。似乎我们现在与百年后同样擅长想象无限资源。  

人们希望编写什么程序？最省力的那种。但不完全——是在不被现有语言观念影响时最省力的那种。这种影响如此 pervasive，需要巨大努力才能克服。你可能会认为，对我们这种懒惰生物而言，用最少努力表达程序应该是显而易见的。事实上，我们对可能性的认知受限于思维语言，更简单的程序表达往往显得惊人——它们是待发现的，而非自然沉浸的。  

一个有用技巧是用程序长度近似衡量编写工作量。当然不是字符长度，而是独立语法元素数量——基本上是语法树大小。最短程序是否对应最少工作量并不绝对，但瞄准简洁这个明确目标比瞄准模糊的“最少工作”更可靠。于是语言设计算法变为：审视程序并询问，是否存在更简短的写法？  

实践中，用假想的百年语言编写程序的可行性取决于你与核心的距离。排序算法现在就能写，但预测百年后需要哪些库则困难——很可能许多库针对尚未出现的领域。例如若SETI@home成功，我们将需要与外星人通信的库。除非他们已先进到使用XML交流。  

另一个极端是，我认为今天就可能设计出核心语言。事实上有人可能主张它早在1958年就已基本设计完成。  

如果百年语言今天可用，我们会想用它编程吗？一种回答方式是回顾历史：如果现代编程语言在1960年就存在，会有人愿意使用吗？  

某些方面答案是否定的。现代语言依赖1960年不存在的设施。例如Python这种依赖缩进的语言在打印终端上难以工作。但抛开这些问题（假设程序都写在纸上），1960年代的程序员会喜欢用我们现在的语言编程吗？  

我认为会的。某些缺乏想象力的程序员（其编程观念被早期语言特性固化）可能会有障碍（没有指针运算如何操作数据？没有goto如何实现流程图？）。但我认为最聪明的程序员若能接触现代语言，定能物尽其用。  

即使现在拥有百年语言，至少它会是优秀的伪代码。用它编写软件呢？既然百年语言需要为某些应用生成快速代码，想必它也能生成在我们硬件上高效运行的代码。我们可能需要比百年后用户提供更多优化建议，但总体上仍可能获益。  

现在有两个观点结合后暗示有趣的可能性：(1)百年语言原则上今天就可设计；(2)这种语言若存在，可能现在就是优秀的编程工具。看到这些观点并列，很难不思考：为何不现在就尝试编写百年语言？  

从事语言设计时，我认为应该确立这样的目标并保持清醒意识。学习驾驶时，重要原则是对准远方某点而非引擎盖与道路标线的相对位置来调整方向——即使你只关心接下来十英尺的路况。我认为编程语言领域同样适用这个原则。  

**注释**  
我相信Lisp Machine Lisp是首个体现“声明（动态变量除外）仅是优化建议，不会改变正确程序含义”原则的语言。Common Lisp似乎是首个明确阐述这点的语言。  

**致谢**  
感谢Trevor Blackwell、Robert Morris和Dan Giffin阅读本文草稿，感谢Guido van Rossum、Jeremy Hylton及Python团队邀请我在PyCon演讲。

你可以在[《黑客与画家》](hackpaint.html)中找到这篇文章以及其他14篇。