---
title: "我从Hacker News学到的东西"
original_title: "What I've Learned from Hacker News"
author: "Paul Graham"
translator: "deepseek-ai/DeepSeek-V3 (SiliconFlow)"
translate_date: "2025-07-14"
source_file: "What I've Learned from Hacker News.md"
---

# 我从Hacker News学到的东西

| | [](index.html)  
  
|   
  
2009年2月  
  
上周是Hacker News成立两周年。最初它只是一个副业项目——一个用来打磨Arc语言的应用，也是当前及未来Y Combinator创始人交流新闻的场所。它的发展规模和我投入的时间都超出了预期，但我并不后悔，因为运营它让我获益良多。  
  
**成长历程**  
  
2007年2月上线时，工作日日均独立访客约为1600人。如今已[增长](http://ycombinator.com/images/2yeartraffic.png)至约22,000人。这个增速略高于我的预期。虽然我希望网站保持增长（因为停滞不前的网站无异于消亡），但我不愿它发展成Digg或Reddit那样的规模——主要担心会稀释网站特色，同时也因不愿将所有时间耗费在扩容问题上。  
  
现有问题已足够棘手。请记住，创建HN的初衷是为了测试一门新编程语言，而且这是一门专注于语言设计实验而非性能优化的语言。每当网站运行迟缓时，我就用McIlroy和Bentley的经典名言来激励自己：  
  
> 性能的关键在于优雅，而非堆砌特例。

这是Paul Graham的文章《我从Hacker News中学到了什么》的第2部分，共3部分。

寻找能用最少代码消除的瓶颈。到目前为止，我还能勉强跟上，尽管用户量增长了14倍，但性能始终维持在中等水平。我不知道下一步该怎么做，但应该能想出办法。

这是我对待这个网站的基本态度。Hacker News是一个实验，而且是一个非常新兴领域的实验。这类网站的历史只有几年。互联网上的对话总体上也只有几十年历史。因此，我们可能只发现了未来将发现的一小部分。

这就是为什么我对HN如此乐观。当一项技术如此年轻，现有的解决方案通常都很糟糕；这意味着一定有办法做得更好；也意味着许多看似无解的问题其实并非如此。包括——我希望——困扰许多前人的问题：因增长而毁灭。

**稀释**

用户从网站成立几个月起就开始担心这个问题。到目前为止这些警报都是虚惊，但未来未必总是如此。稀释是个难题。但或许有解；当“总是”只等于20个案例时，说开放对话“总是”被增长摧毁并没有太大意义。

但重要的是记住我们在尝试解决一个新问题，这意味着我们必须尝试新方法，而大多数可能行不通。几周前我尝试用橙色显示平均评论得分最高的用户名。[1]这是个错误。原本基本团结的文化突然分裂成“有产者”和“无产者”。直到看到分裂，我才意识到原先的团结有多珍贵。这过程令人痛苦。[2]

所以橙色用户名不会再出现。（对此我很抱歉。）但未来还会有其他看似同样糟糕的主意，而最终成功的那些可能和失败的看起来一样糟糕。

关于稀释，我学到最重要的大概是：衡量标准更多在于行为而非用户。你想阻挡的是不良行为，而非不良用户。用户行为出人意料地具有可塑性。如果人们被[期待](http://ycombinator.com/newswelcome.html)表现良好，他们往往会做到；反之亦然。

当然，禁止不良行为确实会赶走不良用户，因为他们在一个需要表现良好的地方感到束缚。但这种阻挡方式比显性屏障更温和，可能也更有效。

现在很清楚，破窗理论也适用于社区网站。该理论认为轻微的不良行为会助长更严重的：一个满是涂鸦和破窗的社区会变成抢劫案高发地。朱利安尼推行让破窗理论闻名的改革时，我住在纽约，那种转变堪称奇迹。而当相反情况发生在Reddit时，我也是一名用户，其转变同样戏剧性。

我并非批评Steve和Alexis。Reddit的遭遇并非因为疏忽。他们从一开始就奉行只屏蔽垃圾信息的政策。此外Reddit的目标与Hacker News不同。Reddit是创业公司，而非副项目；它的目标是尽可能快速增长。快速增长加零审查，结果就是彻底的自由放任。但我不认为他们重来一次会做出多大改变。以流量衡量，Reddit比Hacker News成功得多。

但Reddit的遭遇不一定会降临HN。存在多个局部最优解。可以有彻底自由的空间，也可以有更深思熟虑的空间，就像现实世界一样；人们会根据所处环境调整行为，正如现实世界那样。

我亲眼见过这种现象。有人在Reddit和Hacker News交叉发帖时，会特意写两个版本：Reddit上煽动，HN上克制。

**提交内容**

Hacker News这类网站需要避免两类主要问题：劣质文章和劣质评论。目前劣质文章的风险似乎较小。首页展示的内容仍大致符合HN创立时的标准。

我曾以为需要通过加权投票来屏蔽垃圾内容，但至今尚未实施。我没想到首页能保持得这么好，也不完全明白原因。或许只有更深思熟虑的用户才愿意提交和投票，因此每增加一个随机新用户的边际成本接近零。又或许首页通过展示内容标准实现了自我保护。

首页最危险的莫过于太容易获得投票的内容。如果有人证明新定理，读者需要花些功夫决定是否投票。有趣漫画需要的思考较少。而标题煽动的 rant 则完全不需要，因为人们不读内容就会投票。

因此我提出“泡沫原则”：在用户投票的新闻网站，除非采取特定措施，否则最易评判的链接将占据主导。

HN有两道防线抵御泡沫。最常见的泡沫链接被归类为无关内容禁止发布。小猫图片、政治抨击等被明确禁止。这阻挡了大部分泡沫，但非全部。有些链接既短小（泡沫特征）又主题相关。

对此没有单一解决方案。如果链接只是空洞的 rant，管理员有时会删除，即使它 technically 关于黑客——因为真正标准是激发求知欲。若某网站内容多属此类，我可能封禁其域名，来自该网址的新内容会自动删除。若帖子标题诱导点击，管理员会改为平实表述。这对标题是 rallying cry 的链接尤其必要，否则它们会变成隐形的“认同就点赞”帖子——泡沫的终极形态。

处理链接的技术必须进化，因为链接在进化。聚合器的存在已影响被聚合内容。作者开始为吸引聚合器流量刻意写作——有时甚至针对特定平台。（不，这句话的反讽我没忽略。）还有更恶意的变体，如 linkjacking——转述他人文章后提交 paraphrase 而非原文。这些能获得大量点赞，因为文章精华常被保留；事实上，paraphrase 越接近抄袭，保留越多。[3]

我认为，删除提交的网站必须提供查看被删内容的途径。这既监督管理员，也确保用户相信能察觉管理员的不公。HN用户可通过个人资料中的showdead开关实现。[4]

**评论**

劣质评论似乎比劣质文章更难解决。虽然HN首页链接质量变化不大，但评论的中位数质量可能有所下降。

劣质评论主要有两种：刻薄与愚蠢。两者常重叠——刻薄评论往往也愚蠢——但应对策略不同。刻薄更容易控制。制定禁止刻薄的规则并执行，似乎能有效抑制。

抑制愚蠢更难，或许因愚蠢更难辨别。刻薄者比愚蠢者更容易意识到自己的刻薄。

最危险的愚蠢评论不是长篇大论但错误的观点，而是无聊玩笑。长篇错误观点其实很罕见。评论质量与长度高度相关；若要比较社区网站评论质量，平均长度是良好指标。原因可能在于人性而非评论线程特性。或许愚蠢更多表现为缺乏观点，而非观点错误。

无论原因为何，愚蠢评论往往短小。由于短评难以靠信息量出众，人们转而追求幽默。愚蠢评论最诱人的形式是所谓机智挖苦，可能因挖苦是最简单的幽默。[5]因此禁止刻薄的附带好处是减少这类内容。

劣质评论如同葛藤：会迅速蔓延。评论对新评论的影响远大于文章对新文章的影响。若有人提交低劣文章，其他提交不会集体变差。但若某条评论愚蠢，它会设定周围讨论的基调。人们用无聊玩笑回应无聊玩笑。

或许解决方案是在回复评论前增加延迟，延迟长度与评论质量预测值成反比。这样愚蠢讨论会生长更慢。[6]

**人群**

我注意到所述方法大多保守：旨在保持而非提升网站特质。我不认为这是个人偏见，而是问题本质使然。HN有幸始于良好状态，因此这确实是保存问题。但我认为该原则也适用于不同起源的网站。

社区网站的优质内容更多来自人而非技术；技术主要在预防劣质内容时发挥作用。技术当然能促进讨论。例如嵌套评论。但我宁愿使用功能原始但用户聪明友善的网站，而非功能先进但用户愚蠢或[引战](trolls.html)的平台。

因此社区网站最重要的任务是吸引目标用户。追求最大规模的网站希望吸引所有人。但瞄准特定用户群的网站必须精准吸引——同样重要的是，排斥其他人群。我在HN有意识地这样做。设计尽可能朴素，网站规则反对夸张标题。目标是让首次访问者唯一感兴趣的只能是那里表达的思想。

针对特定人群调整网站的缺点是：对目标人群可能过于吸引。我深知Hacker News有多令人上瘾。对我和许多用户而言，它是虚拟的城镇广场。想休息时，我就走进广场，就像走进现实中的哈佛广场或大学路。[7]但线上广场比实体更危险。若在大学路闲逛半天，我会察觉。去那里要步行一英里，坐在咖啡馆与工作感觉不同。但访问在线论坛只需点击，表面与工作极为相似。你可能在浪费时间，但并非无所事事。网上有人[犯错](http://xkcd.com/386/)，而你正在纠正。

Hacker News无疑有用。我从HN阅读的内容中学到很多。有几篇文章最初是那里的评论。因此我不希望它消失。但我想确认它没有净消耗生产力。若吸引成千上万聪明人到导致他们浪费时间的网站，将是场灾难。我希望能百分百确定这不是HN的写照。

我认为游戏和社交应用的成瘾性仍是未解难题。现状如同1980年代的可卡因：我们发明了极易上瘾的新事物，却尚未进化出自我保护机制。我们终将做到，这是我接下来希望关注的问题之一。

**注释**

[1] 我尝试过按评论得分的平均值和中位数排名，剔除最高分后的平均值对高质量预测更准确。但中位数可能对低质量预测更准。

[2] 这个实验还让我明白：若要对人区分，必须确保方法正确。这是快速原型法不适用的问题。

事实上，反对区别对待的诚实理由是：并非人人相同，而是容易做错且难以做对。

[3] 发现严重 linkjacking 时，我会将网址替换为被抄袭的原链接。惯犯网站会被封禁。

[4] Digg因缺乏透明度声名狼藉。根源并非运营者特别狡猾，而是采用了错误的前页生成算法。与Reddit不同，Digg的故事从顶部开始，被新内容向下推挤。

差异源于Digg继承Slashdot，Reddit继承Delicious/popular。Digg是用投票代替编辑的Slashdot，Reddit是用投票代替书签的Delicious/popular。（从界面设计仍能看出渊源。）

Digg算法极易被操纵，因为任何登上首页的故事都会成为新头条。这迫使Digg采取极端对策。许多初创公司都有早期不得已的秘密手段，我怀疑Digg的是：头条实际由人工编辑选定。

[5] 《瘪四与大头蛋》的对话多属此类，当我在糟糕网站读评论时，能听到他们的声音。

[6] 我认为抑制愚蠢评论的大多数方法尚未被发现。Xkcd在IRC频道实施了特别聪明的一招：禁止重复。一旦有人说“失败”，再无人能说。这会特别惩罚短评，因其更难避免重复。

另一个有前景的主意是[愚蠢过滤器](http://stupidfilter.org)，原理类似概率性垃圾过滤器，但训练数据是愚蠢与非愚蠢评论语料。

或许无需删除劣质评论也能解决问题。长线程底部的评论很少被看到，因此在排序算法中加入质量预测可能足够。

[7] 多数郊区令人沮丧的原因在于没有可步行前往的中心。

**致谢** Justin Kan、Jessica Livingston、Robert Morris、Alexis Ohanian、Emmet Shear和Fred Wilson阅读了本文草稿。

[评论](http://news.ycombinator.com/item?id=495053)本文。

***  
  
---